На данный момент я успел реализовать только вариант для классического ML.

Казалось, что потребуется предварительно очистить данные.
Однако, я ограничился только удалением null'ов и набора данных,
и итоговый результат оказался на удивление неплохим.

В качестве модели я использовал решающие деревья и пробовал
варьировать их максимальную высоту.
min_samples_split я решил оставить маленьким,
его увеличение негативно влияло на точность.
Предполагаю, при небольшом значении этого параметра дереву удавалось
отслеживать редкоиспользуемые искажения токсичной лексики.

У меня не самый мощный ноутбук, поэтому перебирал я достаточно маленькое
количество различных конфигураций.
Изначально я проверил значения max_depth от 1 до 9001 с шагом 1000.
В таком случае я получал явный пик f1_score при значениях в районе 2500.

Полученный в итоге f1_score оказался больше 0.9 в некоторых случаях,
что меня удивляет.
Замечу, что я использовал 35% исходной выборки для тестирования,
а обучение проводилось на других данных.
